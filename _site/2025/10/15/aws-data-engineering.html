<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Building Scalable Data Pipelines on AWS: Lessons Learned | João Capinha's Page</title>
    <link rel="icon" type="image/svg+xml" href="/assets/images/favicon.svg">
    <link rel="stylesheet" href="/assets/css/style.css?v=0d1d0c44885444030a0a41b782ec4f96355ce58f">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="wrapper">
        <nav class="sidebar">
            <ul>
                
                <li><a href="/" >Home</a></li>
                
                <li><a href="/about" >About Me</a></li>
                
                <li><a href="/cv" >CV</a></li>
                
                <li><a href="/blog" >Blog</a></li>
                
                <li><a href="/contacts" >Contacts</a></li>
                
            </ul>
        </nav>
        <div class="content">
            <h1>Building Scalable Data Pipelines on AWS: Lessons Learned</h1>
            <h1 id="building-scalable-data-pipelines-on-aws-lessons-learned">Building Scalable Data Pipelines on AWS: Lessons Learned</h1>

<p>Over the past few years working with BMW Group, I’ve had the opportunity to work on several large-scale data engineering projects. In this post, I’ll share some key insights and lessons learned from building data pipelines on AWS.</p>

<h2 id="the-challenge">The Challenge</h2>

<p>When dealing with vehicle telemetry data, we faced several challenges:</p>
<ul>
  <li>Processing massive amounts of real-time data</li>
  <li>Ensuring data quality and consistency</li>
  <li>Optimizing costs while maintaining performance</li>
  <li>Building maintainable and scalable systems</li>
</ul>

<h2 id="key-solutions">Key Solutions</h2>

<h3 id="1-apache-iceberg-for-data-lake-management">1. Apache Iceberg for Data Lake Management</h3>

<p>One of the most impactful decisions we made was implementing Apache Iceberg. This helped us:</p>
<ul>
  <li>Optimize query performance</li>
  <li>Manage schema evolution</li>
  <li>Improve data lake metadata handling</li>
</ul>

<h3 id="2-real-time-processing-with-apache-kafka">2. Real-time Processing with Apache Kafka</h3>

<p>Using Kafka allowed us to:</p>
<ul>
  <li>Handle high-throughput data streams</li>
  <li>Ensure reliable message delivery</li>
  <li>Decouple data producers and consumers</li>
</ul>

<h2 id="lessons-learned">Lessons Learned</h2>

<ol>
  <li>Start with good data modeling</li>
  <li>Invest in monitoring and observability</li>
  <li>Consider cost implications early</li>
  <li>Build for maintainability</li>
</ol>

<p>[More content to be added…]</p>

        </div>
    </div>
</body>
</html>